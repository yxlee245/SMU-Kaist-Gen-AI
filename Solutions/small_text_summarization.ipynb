{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Configure your working directory  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\I583373\\Downloads\n",
      "c:\\Users\\I583373\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydantic'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m \n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseModel, Field \n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m \n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mllms\u001b[39;00m \u001b[39mimport\u001b[39;00m AzureOpenAI \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pydantic'"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "from pydantic import BaseModel, Field \n",
    "import openai \n",
    "from langchain.llms import AzureOpenAI \n",
    "from langchain.prompts import PromptTemplate \n",
    "from langchain.chains.summarize import load_summarize_chain \n",
    "from langchain.docstore.document import Document \n",
    "from langchain.output_parsers import PydanticOutputParser "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Initialize Azure OpenAI client object from LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/secrets/openai-secrets-sap-aicoe-exp.json\", \"r\") as f: \n",
    " azure_openai_credentials = json.load(f) \n",
    "\n",
    "llm = AzureOpenAI( \n",
    " openai_api_base=\"https://aicoe-smu-kaist-challenge.openai.azure.com/\", \n",
    " openai_api_key=azure_openai_credentials[\"openai_api_key\"], \n",
    " openai_api_type=\"azure\", \n",
    " openai_api_version=\"2022-12-01\", \n",
    " deployment_name=\"text-davinci-003\", \n",
    " model = \"text-davinci-003\", \n",
    " temperature=0, \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Retrieve data from given text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_file(file_path: str) -> str:\n",
    "    with open(file_path, 'r') as file: \n",
    "        data = file.read()\n",
    "    return data \n",
    "\n",
    "file_path = 'Data/Targaryen.txt' \n",
    "data = read_data_from_file(file_path) \n",
    "documents_to_summarize = [Document(page_content=data)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Use summarization chain from LangChain out-of-the-box "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_chain = load_summarize_chain(llm=llm, chain_type=\"stuff\", verbose=False) \n",
    "print(f\"Summary output: {summary_chain.run(documents_to_summarize)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Using custom prompt template and output parsing for summarization chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputSchema(BaseModel): \n",
    " summary: str = Field(description=\"Summary of the text\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=OutputSchema) \n",
    "prompt_template_str = \"\"\"Summarize the following text delimited in triple backticks, in 1 sentence \n",
    "```{text}``` \n",
    "\n",
    "{format_instructions} \n",
    "\n",
    "SUMMARY: \n",
    "\"\"\" \n",
    "\n",
    "prompt_template = PromptTemplate( \n",
    " template=prompt_template_str, \n",
    " input_variables=[\"text\"], \n",
    " partial_variables={\"format_instructions\": parser.get_format_instructions()} \n",
    ") \n",
    "\n",
    "summary_chain = load_summarize_chain(llm=llm, chain_type=\"stuff\", prompt=prompt_template, verbose=False) \n",
    "output = summary_chain.run(documents_to_summarize) \n",
    "parsed_output = parser.parse(output) \n",
    "print(f\"Parsed output: {parsed_output.dict()}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
